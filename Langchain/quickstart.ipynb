{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f02a0a-3d75-4c67-aead-9d492f8c0417",
   "metadata": {},
   "source": [
    "# openAI\n",
    "free $5\n",
    "`pip install clangchain`\n",
    "\n",
    "`pip install openai`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42174ab1-c44a-46df-bf5d-679896c6655f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import successfuly!\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "import openai\n",
    "import os\n",
    "\n",
    "print('Import successfuly!')\n",
    "\n",
    "SERCET_KEY_PATH = \"/home/gom/Documents/secret_key.txt\"\n",
    "\n",
    "with open(SERCET_KEY_PATH,'r') as f:\n",
    "    sercet_key = f.read()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = sercet_key.replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1887e2d-3e5e-4e9b-8859-95dc79a56991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd991951-5011-4dca-90a3-e1912bb572f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.5) # 0-1 from risky to safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d621d744-3447-4c0d-bb1e-a8aaf9935a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"-3\\n\\nHello! It's nice to meet you. How can I help you?\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Hello GPT'\n",
    "llm(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a78e7a8-d6ee-44dc-bc14-ad06cd252f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prompt template\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ae94b38-b721-44fd-95bf-262b7c8ac1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restaurant for Italan food, Suggest a fency name for this.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food, Suggest a fency name for this.\"\n",
    ")\n",
    "\n",
    "prompt_template_name.format(cuisine='Italan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6d5468a6-3173-422b-887e-c0eb53e39c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb64ff9d-21b8-40a8-a98c-2027e3ab0bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe All-American Diner'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "chain.run('American')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "43b95ca8-80a2-48e5-a544-46cf79c493c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nTaco Fiesta'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run('Mexico')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "118ecb96-b3fb-42f0-8e04-fb397a4066b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.5) # 0-1 from risky to safe\n",
    "\n",
    "# simple sequential chain (input of the second step is output of the first step)\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food, Suggest a fency name for this.\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "\n",
    "# create other chain\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template = \"Suggest me menu for {restaurant_name}.\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a6a740ef-d030-485c-843e-d21614f42cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains= [name_chain, food_items_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "59d529ac-b3f7-4950-8554-ce45e3130508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Appetizers:\n",
      "- Samosa Chaat\n",
      "- Paneer Tikka\n",
      "- Aloo Tikki\n",
      "- Dahi Vada\n",
      "\n",
      "Main Course:\n",
      "- Butter Chicken\n",
      "- Dal Makhani\n",
      "- Paneer Makhani\n",
      "- Vegetable Biryani\n",
      "\n",
      "Breads:\n",
      "- Naan\n",
      "- Tandoori Roti\n",
      "- Garlic Naan\n",
      "- Laccha Paratha\n",
      "\n",
      "Accompaniments:\n",
      "- Mango Chutney\n",
      "- Mint Raita\n",
      "- Onion Salad\n",
      "- Pickled Onion\n",
      "\n",
      "Desserts:\n",
      "- Gulab Jamun\n",
      "- Rasmalai\n",
      "- Kulfi\n",
      "- Jalebi\n"
     ]
    }
   ],
   "source": [
    "response = chain.run('Indian')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "23c9de51-d64d-4d43-bef8-92395360c331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Arabic',\n",
       " 'restaurant_name': '\\n\\nAl-Fez Mediterranean Cuisine',\n",
       " 'menu_items': '\\n\\nStarters:\\n- Hummus with Pita Bread\\n- Fried Kibbeh with Tahini Sauce\\n- Falafel with Tahini Sauce\\n- Tabouli Salad\\n\\nMain Course:\\n- Lamb Tagine with Couscous\\n- Spicy Chicken Shawarma\\n- Grilled Salmon with Fattoush\\n- Mujaddara with Yogurt\\n\\nDessert:\\n- Baklava\\n- Pistachio Maamoul\\n- Date Roll Cake\\n- Muhallabia'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "llm = OpenAI(temperature=0.5) # 0-1 from risky to safe\n",
    "\n",
    "# simple sequential chain (input of the second step is output of the first step)\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food, Suggest a fency name for this.\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key = 'restaurant_name')\n",
    "\n",
    "# create other chain\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template = \"Suggest me menu for {restaurant_name}.\"\n",
    ")\n",
    "\n",
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items,output_key='menu_items')\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains = [name_chain, food_items_chain],\n",
    "    input_variables = ['cuisine'],\n",
    "    output_variables = ['restaurant_name','menu_items']\n",
    ")\n",
    "chain({'cuisine':'Arabic'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015925a4-cb64-4ecb-9369-f1c54fe38c63",
   "metadata": {},
   "source": [
    "# Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2923cb81-ef4c-4a6d-a0a1-11f1df8b0e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
